{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61a12d68-0172-44f2-ad87-8f206fc15572",
   "metadata": {},
   "source": [
    "# Regular MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba10864-6102-4909-b819-959daedad1ad",
   "metadata": {},
   "source": [
    "The paper cites using a LeNet for CNN MNIST. Referring to `build_cnn_model_direct_mnist` in `model_builders.py`:\n",
    "\n",
    "```python\n",
    "with tf.name_scope('net') as scope:\n",
    "    xx = Convolution2D(16, kernel_size=3, strides=1, init='he_normal', padding='valid', activation='relu', kernel_regularizer=l2(weight_decay))(preproc_images)\n",
    "    xx = Convolution2D(16, 3, 3, init='he_normal', padding='valid', activation='relu', kernel_regularizer=l2(weight_decay))(xx)\n",
    "    xx = MaxPooling2D((2, 2))(xx)\n",
    "    xx = Convolution2D(16, 3, 3, init='he_normal', padding='valid', activation='relu', kernel_regularizer=l2(weight_decay))(xx)\n",
    "    xx = BatchNormalization(momentum=0.5)(xx)\n",
    "    xx = Convolution2D(16, 3, 3, init='he_normal', padding='valid', activation='relu', kernel_regularizer=l2(weight_decay))(xx)  # (8, 8)\n",
    "    xx = MaxPooling2D((2, 2))(xx)  # (4, 4)\n",
    "    xx = Flatten()(xx)\n",
    "    xx = Dense(800, kernel_initializer='he_normal', activation='relu', kernel_regularizer=l2(weight_decay))(xx)\n",
    "    xx = Dense(800, kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(xx)\n",
    "    xx = BatchNormalization(momentum=0.5)(xx)\n",
    "    xx = Activation('relu')(xx)\n",
    "    xx = Dense(500, kernel_initializer='he_normal', activation='relu', kernel_regularizer=l2(weight_decay))(xx)\n",
    "    logits = Dense(10, kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(xx)\n",
    "    model = ExtendedModel(input=input_images, output=logits)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6104ed0a-4462-42ef-b02f-7c4249e4377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347ad6d4-04a6-40a4-aaf9-9bd6ea747256",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa0fa5c3-589b-4e49-8ff1-3af06c74ab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(), \n",
    "    # torchvision.transforms.Lambda(lambda x: torch.flatten(x))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bffac591-732e-47f3-862d-37823ab93294",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torchvision.datasets.MNIST(\n",
    "    root=\"~/.torchdata/\", download=False, \n",
    "    # natively stored as PIL images\n",
    "    transform=dataset_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de3256fe-f974-4613-9188-2957b501443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torchvision.datasets.MNIST(\n",
    "    root=\"~/.torchdata/\", download=False, \n",
    "    train=False,\n",
    "    transform=dataset_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "309a3d11-8b0a-4c59-82f1-4b439623e6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: /home/tnwei/.torchdata/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04409cba-e2e9-4180-96cc-478462059e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: /home/tnwei/.torchdata/\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64d4dad6-9b8a-4012-8402-eb06e00fcd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "af8de4cf-bd13-4aa2-bec5-a0d52c559e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=100, shuffle=True)\n",
    "# Returns (torch.Size([100, 784]), torch.Size([100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5431e35c-cc76-4277-8dd6-59ff28c1f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test, batch_size=500, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a848971a-7a45-47a7-9139-3a84489238c3",
   "metadata": {},
   "source": [
    "## Net definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f3bac57-2176-45c8-b83e-9b8c434cc483",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaperLeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Paper cites using LeNet arch\n",
    "        ref: https://arxiv.org/pdf/1804.08838.pdf\n",
    "        \n",
    "        But from the implementation in github, this isn't exactly LeNet:\n",
    "        https://github.com/uber-research/intrinsic-dimension/blob/9754ebe1954e82973c7afe280d2c59850f281dca/intrinsic_dim/model_builders.py#L347\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(3, 3), stride=1, padding=\"valid\")\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), stride=3, padding=\"valid\")\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), stride=3, padding=\"valid\")\n",
    "        \n",
    "        # num_features is out_channels of prev conv?\n",
    "        # at this point, the network has a 32x32 image reduced to 1x1!\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=16, momentum=0.5) \n",
    "        self.conv4 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), stride=3, padding=\"valid\")\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        \n",
    "        self.flatten1 = nn.Flatten()\n",
    "        \n",
    "        self.dense1 = ()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        x = self.flatten1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf6465f-43b7-438a-99fd-1a4392926344",
   "metadata": {},
   "source": [
    "The current net above is a portion of the Tensorflow net replicated. The conv layer after the batchnorm simply doesn't have enough strides to work on! I double checked to ensure that I was reading keras docs correctly. Strange. \n",
    "\n",
    "```python\n",
    "LeNet()(torch.randn(10, 1, 28, 28))\n",
    "---------------------------------------------------------------------------\n",
    "RuntimeError                              Traceback (most recent call last)\n",
    "/tmp/ipykernel_48053/620529947.py in <module>\n",
    "----> 1 LeNet()(torch.randn(10, 1, 28, 28))\n",
    "\n",
    "~/miniconda3/envs/gan/lib/python3.9/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)\n",
    "   1100         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n",
    "   1101                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
    "-> 1102             return forward_call(*input, **kwargs)\n",
    "   1103         # Do not call functions when jit is used\n",
    "   1104         full_backward_hooks, non_full_backward_hooks = [], []\n",
    "\n",
    "/tmp/ipykernel_48053/700110480.py in forward(self, x)\n",
    "     32         x = self.conv3(x)\n",
    "     33         x = self.bn1(x)\n",
    "---> 34         x = self.conv4(x)\n",
    "     35         x = self.maxpool2(x)\n",
    "     36 \n",
    "\n",
    "~/miniconda3/envs/gan/lib/python3.9/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)\n",
    "   1100         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n",
    "   1101                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
    "-> 1102             return forward_call(*input, **kwargs)\n",
    "   1103         # Do not call functions when jit is used\n",
    "   1104         full_backward_hooks, non_full_backward_hooks = [], []\n",
    "\n",
    "~/miniconda3/envs/gan/lib/python3.9/site-packages/torch/nn/modules/conv.py in forward(self, input)\n",
    "    444 \n",
    "    445     def forward(self, input: Tensor) -> Tensor:\n",
    "--> 446         return self._conv_forward(input, self.weight, self.bias)\n",
    "    447 \n",
    "    448 class Conv3d(_ConvNd):\n",
    "\n",
    "~/miniconda3/envs/gan/lib/python3.9/site-packages/torch/nn/modules/conv.py in _conv_forward(self, input, weight, bias)\n",
    "    440                             weight, bias, self.stride,\n",
    "    441                             _pair(0), self.dilation, self.groups)\n",
    "--> 442         return F.conv2d(input, weight, bias, self.stride,\n",
    "    443                         self.padding, self.dilation, self.groups)\n",
    "    444 \n",
    "\n",
    "RuntimeError: Calculated padded input size per channel: (1 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d490e4-30ec-4e79-8081-d865b7667e0b",
   "metadata": {},
   "source": [
    "The LeNet used in this paper isn't exactly a LeNet. There's a batchnorm mixed in in a really weird place. \n",
    "\n",
    "I prefer building a classic LeNet from other sources. Found the original paper on LeCun's personal website at http://yann.lecun.org/exdb/publis/pdf/lecun-89e.pdf. The individual neurons are described specifically in non-deep learning lingo, which makes it a bit difficult to read.\n",
    "\n",
    "[PyImageSearch](https://www.pyimagesearch.com/2021/07/19/pytorch-training-your-first-convolutional-neural-network-cnn/) describes LeNet in a tutorial. The overall arch looks similar to the OG implementation, just that can't be sure on the exact parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1bacb6f4-14cd-4e80-8df6-151749e9f330",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        LeNet from PyImageSearch:\n",
    "        https://www.pyimagesearch.com/2021/07/19/pytorch-training-your-first-convolutional-neural-network-cnn/\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=(5, 5), stride=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=(5, 5), stride=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        self.flatten1 = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=800, out_features=500)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.fc2 = nn.Linear(in_features=500, out_features=10)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        x = self.flatten1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.logsoftmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de2bbbf-494d-4a3b-bff3-9bd8537cc23a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "08e4235a-2e6c-43c4-aba6-80b6748ed258",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LeNet()\n",
    "opt = torch.optim.Adam(net.parameters(), lr=1e-2)\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "749fa43d-d87c-4dee-bdac-17804aa826ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = []\n",
    "acc_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2852528f-94eb-42f8-b0d8-149325638b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3076186180114746\n",
      "0.391210675239563\n",
      "0.389596551656723\n",
      "0.375776469707489\n",
      "0.14125771820545197\n",
      "0.23916095495224\n",
      "0.13795307278633118\n",
      "0.17592500150203705\n",
      "0.2031337320804596\n",
      "0.10884179174900055\n",
      "0.2261829376220703\n",
      "0.17889922857284546\n",
      "0.1087673157453537\n",
      "0.11061125993728638\n",
      "0.18922947347164154\n",
      "0.08641938120126724\n",
      "0.18402229249477386\n",
      "0.22066231071949005\n",
      "0.1210862323641777\n",
      "0.05056007206439972\n",
      "0.11251470446586609\n",
      "0.14379653334617615\n",
      "0.12517106533050537\n",
      "0.05036019906401634\n",
      "0.16461332142353058\n",
      "0.1605762243270874\n",
      "0.11386830359697342\n",
      "0.1159994974732399\n",
      "0.05315348133444786\n",
      "0.14150004088878632\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "net.train()\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    for batch_id, (features, target) in enumerate(train_loader):\n",
    "        # forward pass, calculate loss and backprop!\n",
    "        opt.zero_grad()\n",
    "        preds = net(features)\n",
    "        loss = F.nll_loss(preds, target)\n",
    "        loss.backward()\n",
    "        loss_history.append(loss.item())\n",
    "        opt.step()\n",
    "\n",
    "        if batch_id % 100 == 0:\n",
    "            print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "852cc5e9-cb0b-450d-9f1a-68a0a1741fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1356, Accuracy: 9577/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "net.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "for features, target in test_loader:\n",
    "    output = net(features)\n",
    "    test_loss += F.nll_loss(output, target).item()\n",
    "    pred = torch.argmax(output, dim=-1) # get the index of the max log-probability\n",
    "    correct += pred.eq(target).cpu().sum()\n",
    "\n",
    "test_loss = test_loss\n",
    "test_loss /= len(test_loader) # loss function already averages over batch size\n",
    "accuracy = 100. * correct / len(test_loader.dataset)\n",
    "acc_history.append(accuracy)\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59714fa9-8497-4487-b0ac-cba9f8ecf101",
   "metadata": {},
   "source": [
    "No surprises here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gan]",
   "language": "python",
   "name": "conda-env-gan-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
