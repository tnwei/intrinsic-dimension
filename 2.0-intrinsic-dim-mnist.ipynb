{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61a12d68-0172-44f2-ad87-8f206fc15572",
   "metadata": {},
   "source": [
    "# MNIST with limited intrinsic dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619523cc-67e7-427f-b076-e41e5cc6f6ef",
   "metadata": {},
   "source": [
    "The math in the paper doesn't seem too daunting. Hope I'm not wrong.\n",
    "\n",
    "Normal training is taking the gradient of the loss wrt the weights in its native dimension D, and then perturbing the weights within that space. \n",
    "\n",
    "Training within a random subspace is \n",
    "\n",
    "$$ \\theta ^ D = \\theta_0^D + P \\theta ^ d  $$\n",
    "\n",
    "Where:\n",
    "+ $\\theta ^ D$ is the weights in its native dimension\n",
    "+ $\\theta_0 ^ D$ is the initialized and frozen weights\n",
    "+ $P$ is a randomly generated $D \\times d$ projection matrix, frozen\n",
    "+ $\\theta ^ d$ is the effective weights in a downscaled dimension, that is updated on every loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba10864-6102-4909-b819-959daedad1ad",
   "metadata": {},
   "source": [
    "Cobbled together a regular MNIST training loop, referring to:\n",
    "+ https://gist.github.com/kdubovikov/eb2a4c3ecadd5295f68c126542e59f0a\n",
    "+ https://github.com/uber-research/intrinsic-dimension/blob/master/intrinsic_dim/model_builders.py#L81\n",
    "+ https://arxiv.org/pdf/1804.08838.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a224a3-7867-4640-a88f-2691f8b99d1e",
   "metadata": {},
   "source": [
    "## Figuring out how to incorporate the subspace training logic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651be4cc-6b39-440f-8eb2-88cdb3290e1f",
   "metadata": {},
   "source": [
    "Reading the code on a second pass, found that the individual layers are wrapped in custom projected layers, e.g,:\n",
    "\n",
    "```python\n",
    "# ref: https://github.com/uber-research/intrinsic-dimension/blob/master/intrinsic_dim/model_builders.py\n",
    "from keras_ext.layers import RProjDense, OffsetCreatorDenseProj\n",
    "from keras_ext.engine import ExtendedModel\n",
    "offset_creator_class = OffsetCreatorDenseProj\n",
    "\n",
    "# this chunk is pulled from definition of `build_model_mnist_fc`\n",
    "for _ in range(depth):\n",
    "    xx = RProjDense(\n",
    "        offset_creator_class, vv, width, activation='relu', \n",
    "        kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay)\n",
    "    )(xx)\n",
    "\n",
    "logits = RProjDense(\n",
    "    offset_creator_class, vv, 10, kernel_initializer='he_normal', \n",
    "    kernel_regularizer=l2(weight_decay)\n",
    ")(xx)\n",
    "model = ExtendedModel(input=input_images, output=logits)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4fbaa5-4ace-4ffc-a50e-4a74a6fe4bfc",
   "metadata": {},
   "source": [
    "The whole reason there's so much code lying around is probably due to the custom layers needed for keras. Reading the definitions in https://github.com/uber-research/intrinsic-dimension/blob/master/keras_ext/rproj_layers.py, the custom layers subclass the keras Layer object, modifying `add_weight` and `add_non_trainable_weight` to allow for the subspace training operation. There is a custom layer for each normal layer used! Dense, Dense2D, BatchNorm etc.\n",
    "\n",
    "This is a lot of customization that needs to be piled on before using it, finding intrinsic dimension being a iterative process notwithstanding.\n",
    "\n",
    "I suppose using Keras for research is bound to require shims and splints. Subclassing the Pytorch layers is doable too, but hopefully there is another way to approach it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa88be4c-df21-406d-bd8e-7df39a245ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "371837f7-472b-41f6-810a-271c03fa4757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b74667-1da4-4766-bc9e-a3d15efb4555",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17f5a7f7-4ea5-4fcf-a30b-bb4f615fe936",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Lambda(lambda x: torch.flatten(x))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98c7a272-0e0a-4024-ba2a-2d940322421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torchvision.datasets.MNIST(\n",
    "    root=\"~/.torchdata/\", download=False, \n",
    "    # natively stored as PIL images\n",
    "    transform=dataset_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca151cfc-b701-484f-9e69-b66f28f7931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torchvision.datasets.MNIST(\n",
    "    root=\"~/.torchdata/\", download=False, \n",
    "    train=False,\n",
    "    transform=dataset_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8cc0e6c-816d-43ab-9ab4-bd206a20babf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: /home/tnwei/.torchdata/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Lambda()\n",
       "           )"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc65c296-3f11-4a29-8abc-19c46f049308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: /home/tnwei/.torchdata/\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Lambda()\n",
       "           )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5f61b17-3163-47ce-aa29-232d1b3184e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73123905-463b-484d-a09c-90d035372ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=100, shuffle=True)\n",
    "# Returns (torch.Size([100, 784]), torch.Size([100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "373185f2-8f5a-4dce-8ca0-17827b813f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test, batch_size=500, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a2a7d5-e02f-47c2-b7d6-3b3e7a9087d8",
   "metadata": {},
   "source": [
    "## Custom blocks with subspace training - Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deec7f45-1680-4795-9e32-9f85695f0260",
   "metadata": {},
   "source": [
    "Referred to how torch.nn.Linear is implemeneted at https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html#Linear, I think it is possible to implement a drop-in replacement layer for `nn.Linear`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22e3122c-6f25-4e6d-80fe-33926e2830e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubspaceLinear(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features, out_features, \n",
    "        subspace_features, # this is new!\n",
    "        bias: bool = True, # the rest is by the numbers\n",
    "        device = None,\n",
    "        dtype = None\n",
    "    ):\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "\n",
    "        super().__init__() \n",
    "        \n",
    "        # Mirror nn.Linear init\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.subspace_features = subspace_features\n",
    "        \n",
    "        # Not a Parameter!\n",
    "        self.theta = torch.empty((out_features, in_features), **factory_kwargs)\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        nn.init.kaiming_uniform_(self.theta, a=math.sqrt(5))\n",
    "\n",
    "        # After init, save fixed weights\n",
    "        self.theta_zero = self.theta.detach().clone()\n",
    "        \n",
    "        # Generate projection matrix\n",
    "        self.proj_mat = torch.empty((out_features, subspace_features), **factory_kwargs)\n",
    "        nn.init.kaiming_uniform_(self.proj_mat, a=math.sqrt(5))\n",
    "        # TODO: Init this properly\n",
    "        \n",
    "        # Init theta prime, which will be actually used\n",
    "        self.theta_prime = Parameter(torch.empty((subspace_features, in_features), **factory_kwargs))\n",
    "    \n",
    "        # According to https://pytorch.org/docs/stable/generated/torch.nn.functional.linear.html\n",
    "        # Weight has shape (out_features, in_features)\n",
    "        # Therefore P x theta_prime is:\n",
    "        # (out_features, subspace_features) X (subspace_features, in_features)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self) -> None:\n",
    "        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n",
    "        # uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\n",
    "        # https://github.com/pytorch/pytorch/issues/57109\n",
    "        \n",
    "        nn.init.kaiming_uniform_(self.theta_prime, a=math.sqrt(5))\n",
    "        \n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.theta)\n",
    "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # in nn.Linear:\n",
    "        # return F.linear(x, self.weight, self.bias)\n",
    "        theta = self.theta_zero + torch.mm(self.proj_mat, self.theta_prime)\n",
    "        return F.linear(x, theta, self.bias)\n",
    "    \n",
    "    def extra_repr(self) -> str:\n",
    "        return 'in_features={}, out_features={}, subspace_features={}, bias={}'.format(\n",
    "            self.in_features, self.out_features, self.subspace_features, self.bias is not None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32caea80-0368-4952-99da-7671dc1a6b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sslinear = SubspaceLinear(in_features=100, out_features=2, subspace_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08fb78c3-eda4-4c93-868b-b080e1a77c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias torch.Size([2])\n",
      "theta_prime torch.Size([10, 100])\n"
     ]
    }
   ],
   "source": [
    "for i, j in sslinear.named_parameters():\n",
    "    print(i, j.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15eb70a3-24bd-4840-a08d-1ea13bf6a09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 100]), torch.Size([2, 10]), torch.Size([10, 100]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sslinear.theta_zero.shape, sslinear.proj_mat.shape, sslinear.theta_prime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1072036-612c-44a3-8cb6-b98c91825496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.mm(sslinear.proj_mat, sslinear.theta_prime) + sslinear.theta_zero).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875e4ffd-ba43-410f-b7a6-22dda09edf5d",
   "metadata": {},
   "source": [
    "The repo README refers to three random projection types: denseproj, sparseproj, and fastfoodproj. The dense projection code does not have specific inits for the theta prime tensor. So, subspace projection here should be good ... ? There must be a reason why fastfood transform exists, but that's for later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f50be0-b8d8-4580-9ffb-3bfac03b071d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Combine into net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8be27127-a6db-4fdb-8cd2-3eb73b0a1f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubspaceConstrainedMNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Paper uses 784-200-200-10\n",
    "        ref: https://arxiv.org/pdf/1804.08838.pdf\n",
    "        \n",
    "        Ref in github:\n",
    "        https://github.com/uber-research/intrinsic-dimension/blob/9754ebe1954e82973c7afe280d2c59850f281dca/intrinsic_dim/model_builders.py#L81\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden1 = SubspaceLinear(784, 200, subspace_features=1)\n",
    "        self.hidden2 = SubspaceLinear(200, 10, subspace_features=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.log_softmax(x, dim=-1)  # (batch_size, dims)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16bfeb0-aba0-4b5c-a139-65b470236558",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "368116d2-3598-4aeb-9d8e-d8f5b6e15cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SubspaceConstrainedMNIST()\n",
    "opt = torch.optim.Adam(net.parameters(), lr=1e-4)\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7bca7e83-75bd-4ff1-9a66-4b79ca6c7f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden1.bias torch.Size([200])\n",
      "hidden1.theta_prime torch.Size([1, 784])\n",
      "hidden2.bias torch.Size([10])\n",
      "hidden2.theta_prime torch.Size([1, 200])\n"
     ]
    }
   ],
   "source": [
    "for i, j in net.named_parameters():\n",
    "    print(i, j.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "171a0b99-c10a-4b1f-bfcd-b8385f7ef317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200])\n",
      "torch.Size([1, 784])\n",
      "torch.Size([10])\n",
      "torch.Size([1, 200])\n"
     ]
    }
   ],
   "source": [
    "for j in net.parameters():\n",
    "    print(j.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4cd146ca-6bc7-4583-8111-7590cb11cc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = []\n",
    "acc_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "075389f4-e214-432b-8c2f-c0d38a61f665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.302417278289795\n",
      "100 2.2474958896636963\n",
      "200 2.229177951812744\n",
      "300 2.1434550285339355\n",
      "400 2.1148269176483154\n",
      "500 1.9995251893997192\n",
      "0 1.9329489469528198\n",
      "100 1.9272170066833496\n",
      "200 1.9117159843444824\n",
      "300 1.8802971839904785\n",
      "400 1.8392847776412964\n",
      "500 1.906437635421753\n",
      "0 1.8706496953964233\n",
      "100 1.8790347576141357\n",
      "200 1.8126376867294312\n",
      "300 1.8047877550125122\n",
      "400 1.8428906202316284\n",
      "500 1.8741843700408936\n",
      "0 1.8446906805038452\n",
      "100 1.802445888519287\n",
      "200 1.7921345233917236\n",
      "300 1.837571382522583\n",
      "400 1.795865774154663\n",
      "500 1.8554120063781738\n",
      "0 1.8762071132659912\n",
      "100 1.7685798406600952\n",
      "200 1.7978787422180176\n",
      "300 1.8438409566879272\n",
      "400 1.708366870880127\n",
      "500 1.735275387763977\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "net.train()\n",
    "first_ten_flag = False\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    for batch_id, (features, target) in enumerate(train_loader):\n",
    "        # forward pass, calculate loss and backprop!\n",
    "        opt.zero_grad()\n",
    "        preds = net(features)\n",
    "        loss = F.nll_loss(preds, target)\n",
    "        loss.backward()\n",
    "        loss_history.append(loss.item())\n",
    "        opt.step()\n",
    "\n",
    "        if (batch_id % 100 == 0):\n",
    "            print(batch_id, loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a29387e-9693-4cd4-90db-df0e2e5d3779",
   "metadata": {},
   "source": [
    "The network was giving NaN loss. Forked into 2.1 to troubleshoot, turns out I forgot to init the projection matrix. Once put that in, the network seems to be doing OK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7570f983-25eb-4498-bae1-b346faa1bf4b",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4262bb00-da2d-4151-ac7a-9ab68ea05a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.7814, Accuracy: 3328/10000 (33%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "for features, target in test_loader:\n",
    "    output = net(features)\n",
    "    test_loss += F.nll_loss(output, target).item()\n",
    "    pred = torch.argmax(output, dim=-1) # get the index of the max log-probability\n",
    "    correct += pred.eq(target).cpu().sum()\n",
    "\n",
    "test_loss = test_loss\n",
    "test_loss /= len(test_loader) # loss function already averages over batch size\n",
    "accuracy = 100. * correct / len(test_loader.dataset)\n",
    "acc_history.append(accuracy)\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4b4600-fca9-474a-ace0-1b62d67d772d",
   "metadata": {},
   "source": [
    "Varied the subspace dimension a few times but not much change. Realized that at subspace features = 1, there is still many degrees of freedom left! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "87956358-8c8c-4c33-b6b4-ec4f6a8eafd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden1.bias torch.Size([200])\n",
      "hidden1.theta_prime torch.Size([1, 784])\n",
      "hidden2.bias torch.Size([10])\n",
      "hidden2.theta_prime torch.Size([1, 200])\n"
     ]
    }
   ],
   "source": [
    "for i, j in net.named_parameters():\n",
    "    print(i, j.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcadfc0-b077-4a3d-b39f-a24bdc154b52",
   "metadata": {},
   "source": [
    "$1x784 + 1x200 = 984$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb310e9-ef57-4d3d-b148-816ed0704555",
   "metadata": {},
   "source": [
    "Gotta see how the repo constrains degrees of freedom properly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:drift]",
   "language": "python",
   "name": "conda-env-drift-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
